{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEw0YFHgBArS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzdxpSfXBGVB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uO91sTbBl2n"
      },
      "outputs": [],
      "source": [
        "def indexOf(d,v): # d là một dictionary, v là một feature.\n",
        "  for i in d:\n",
        "    if (i == v):\n",
        "        return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQwmn7K3BnN0"
      },
      "outputs": [],
      "source": [
        "def get_feature(tree):\n",
        "  features = [i for i in tree.tree_.feature]\n",
        "  featureIndex = [num for num in features if num != -2]\n",
        "  return featureIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiTGR0znBoxo"
      },
      "outputs": [],
      "source": [
        "def get_featureFirst(d,n):\n",
        "  number = n if n < len(d) else len(d)\n",
        "  count = 0\n",
        "  arr = []\n",
        "  for key, v in d:\n",
        "    if (count < number):\n",
        "      arr.append(key)\n",
        "      count = count + 1\n",
        "    else:\n",
        "      break\n",
        "  return arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBrz8VMFBqEk"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/data/datafs/colon1.csv\")\n",
        "X = data.iloc[:,1:]\n",
        "y = data.iloc[:,0]\n",
        "d = {}\n",
        "for i in range(50):\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=np.random.randint(0,10000), stratify = y)\n",
        "  rf_model = RandomForestClassifier() # default create 100 trees\n",
        "  rf_model.fit(X_train, y_train)\n",
        "  for idx, dtree in enumerate(rf_model.estimators_):\n",
        "      a = get_feature(tree = dtree)\n",
        "      for i in a: # a là một list features trong model.\n",
        "        if(indexOf(d, i)):\n",
        "          number = d.get(i)\n",
        "          number = number + 1\n",
        "          d[i] = number\n",
        "        else:\n",
        "          d.update({i:1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsY1h_lsBzVJ"
      },
      "outputs": [],
      "source": [
        "X_original = data.iloc[:,1:]\n",
        "y = data.iloc[:,0]\n",
        "c_original = X_original.shape[1]\n",
        "number_feat_selected = round(c_original * 1/100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQkyV1nGCyHR"
      },
      "outputs": [],
      "source": [
        "number = round(c_original * 5/100)\n",
        "a = sorted(d.items(), key = lambda item: item[1], reverse = True)\n",
        "index_5_percent = get_featureFirst(a,number) # top 5% features\n",
        "top_5_percent_feature_names = X.columns[index_5_percent]\n",
        "X_new = X_original.iloc[:,index_5_percent] # dataframe use 5% features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4PVIUuqTRpl"
      },
      "outputs": [],
      "source": [
        "list_values = {}\n",
        "list_values.update({\n",
        "    \"X\": X,\n",
        "    \"y\": y,\n",
        "    \"d\": d,\n",
        "    \"number_feat_selected\": number_feat_selected, # top 1%\n",
        "    \"top_5_percent_feature_names\": top_5_percent_feature_names,\n",
        "    \"X_new\": X_new\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O_1c469G5DB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times = {}\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0q2DVbgbra5"
      },
      "source": [
        "# **Filter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "550-LKFqFOWJ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "import pandas as pd\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "\n",
        "# Mutual Information\n",
        "from sklearn.feature_selection import mutual_info_classif as mic\n",
        "start_time = time.time()\n",
        "importances = mic(list_values[\"X_new\"],list_values[\"y\"])\n",
        "IG_feature_names = pd.Series(importances, index = list_values[\"X_new\"].columns).sort_values(ascending = False).head(list_values[\"number_feat_selected\"]).index #ascending  = False nghĩa là sẽ sắp xếp các giá trị nhỏ dần, lấy tên features\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"IG_feature_names\"] = IG_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"IG_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UUKpNnB6Cua"
      },
      "outputs": [],
      "source": [
        "pip install skfeature-chappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H9vdzoqL3yE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pickle\n",
        "import time\n",
        "import pandas as pd\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "\n",
        "#Fisher's score\n",
        "from skfeature.function.similarity_based import fisher_score\n",
        "X_new_FS = list_values[\"X_new\"].to_numpy()\n",
        "y_FS = list_values[\"y\"].to_numpy()\n",
        "\n",
        "start_time = time.time()\n",
        "ranks = fisher_score.fisher_score(X_new_FS, y_FS)\n",
        "Fish_feature_names = pd.Series(ranks, index = list_values[\"X_new\"].columns).sort_values(ascending = False).head(list_values[\"number_feat_selected\"]).index\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"Fish_feature_names\"] = Fish_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"Fish_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7QxvUERL36U"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import time\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "\n",
        "#Pearson Correlation\n",
        "X_new_corr = list_values[\"X_new\"].copy()\n",
        "X_new_corr['class'] = list_values[\"y\"]\n",
        "start_time = time.time()\n",
        "corr = X_new_corr.corr()\n",
        "high_corr_features = corr['class'].abs().drop('class') # xóa tương quan của class\n",
        "Corr_feature_names = pd.Series(high_corr_features, index = list_values[\"X_new\"].columns).sort_values(ascending = False).head(list_values[\"number_feat_selected\"]).index\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"Corr_feature_names\"] = Corr_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"Corr_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrY3rOU1q681"
      },
      "source": [
        "# **WRAPPER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKCS9Kjw1h4d"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "#forward\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "start_time = time.time()\n",
        "lr = LogisticRegression()\n",
        "ffs = SequentialFeatureSelector(lr, k_features= list_values[\"number_feat_selected\"], forward = True, n_jobs = -1) # n_jobs = -1: chỉ định số jobs được thực hiện cùng lúc.\n",
        "ffs.fit(list_values[\"X_new\"],list_values[\"y\"])\n",
        "For_feature_names= list(ffs.k_feature_names_)\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"For_feature_names\"] = For_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"For_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D457oOSl1jJj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "#backward\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "start_time = time.time()\n",
        "lr = LogisticRegression()\n",
        "lr.fit(list_values[\"X_new\"],list_values[\"y\"])\n",
        "bfs = SequentialFeatureSelector(lr, k_features = list_values[\"number_feat_selected\"], forward = False, n_jobs = -1)\n",
        "bfs.fit(list_values[\"X_new\"],list_values[\"y\"])\n",
        "Back_feature_names = bfs.k_feature_names_\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"Back_feature_names\"] = Back_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"Back_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3GNMJG7MKv1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "#Recursive feature elimmination\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "start_time = time.time()\n",
        "lr = LogisticRegression()\n",
        "rfe = RFE(lr, n_features_to_select = list_values[\"number_feat_selected\"])\n",
        "rfe.fit(list_values[\"X_new\"],list_values[\"y\"])\n",
        "Rec_feature_names = list_values[\"X_new\"].columns[rfe.support_].tolist()\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"Rec_feature_names\"] = Rec_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"Rec_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH7rhsCoq_OO"
      },
      "source": [
        "# **EMBEDDED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St1mjuG23mFv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'rb') as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'rb') as file:\n",
        "  list_times = pickle.load(file)\n",
        "#LASSO\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "start_time = time.time()\n",
        "logistic = LogisticRegression(penalty = 'l1', solver = 'liblinear', random_state = np.random.randint(0,10000)).fit(list_values[\"X_new\"],list_values[\"y\"]) # l1: là chỉ ra sẽ sử dụng lasso, solver = 'liblinear': được sử dụng để model tìm các hệ số tối ưu.\n",
        "model = SelectFromModel(logistic, prefit = True) # prefit = True nghĩa là đã huấn luyện model từ trước, nên khi cho vào chỉ việc giảm feature.\n",
        "X_new_lasso = model.transform(list_values[\"X_new\"])\n",
        "selected_features = list_values[\"X_new\"].columns[model.get_support()] # gets the names of the selected features\n",
        "coefficients = logistic.coef_[0][model.get_support()] # gets the coefficients of the selected features\n",
        "features_coefficients = pd.DataFrame({'feature': selected_features, 'coefficient': coefficients})\n",
        "features_coefficients = features_coefficients.reindex(features_coefficients.coefficient.abs().sort_values(ascending=False).index)\n",
        "top_features = features_coefficients.head(list_values[\"number_feat_selected\"])\n",
        "Lasso_feature_names = top_features['feature'].values\n",
        "end_time = time.time()\n",
        "elapsed_time = round(end_time - start_time, 3)\n",
        "\n",
        "list_values[\"Lasso_feature_names\"] = Lasso_feature_names\n",
        "with open('/content/drive/My Drive/data/list_values3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_values, file)\n",
        "\n",
        "list_times[\"Lasso_time\"] = elapsed_time\n",
        "with open('/content/drive/My Drive/data/list_times3.pkl', 'wb') as file:\n",
        "  pickle.dump(list_times, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuXEcPwLTy4p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/My Drive/data/list_values3.pkl\", \"rb\") as file:\n",
        "  list_values = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "classifiers = {\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'SVC': SVC(),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "\n",
        "feature_methods = {\n",
        "'all': None,  # Using all features\n",
        "'5%': list_values[\"top_5_percent_feature_names\"] ,\n",
        "'IG': list_values[\"IG_feature_names\"] ,\n",
        "'CHI': list_values[\"Chi2_feature_names\"] ,\n",
        "'FISH': list_values[\"Fish_feature_names\"] ,\n",
        "'CORR': list_values[\"Corr_feature_names\"] ,\n",
        "'VAR': list_values[\"Var_feature_names\"] ,\n",
        "'MAD': list_values[\"MAD_feature_names\"]  ,\n",
        "'DIS': list_values[\"Dis_feature_names\"] ,\n",
        "'FOR': list_values[\"For_feature_names\"] ,\n",
        "'BACK': list(list_values[\"Back_feature_names\"]) ,\n",
        "'RECURSIVE': list_values[\"Rec_feature_names\"] ,\n",
        "'LASSO': list_values[\"Lasso_feature_names\"]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(clf, X_train, y_train, X_test, y_test):\n",
        "    clf.fit(X_train, y_train.values.ravel())\n",
        "    return accuracy_score(y_test, clf.predict(X_test))\n",
        "\n",
        "\n",
        "accuracies = {method: {clf: [] for clf in classifiers} for method in feature_methods}\n",
        "\n",
        "\n",
        "for i in range(50):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(list_values[\"X\"] , list_values[\"y\"] , train_size=0.7, random_state=np.random.randint(0, 10000), stratify = list_values[\"y\"]) # X,y là từ data ban đầu\n",
        "\n",
        "    for method, feature_names in feature_methods.items():\n",
        "      if method == 'all':\n",
        "        X_train_method =  X_train\n",
        "        X_test_method  =  X_test\n",
        "      else:\n",
        "        X_train_method = X_train[feature_names]\n",
        "        X_test_method = X_test[feature_names]\n",
        "      for clf_name, clf in classifiers.items():\n",
        "        acc = evaluate_model(clf, X_train_method, y_train, X_test_method, y_test)\n",
        "        accuracies[method][clf_name].append(acc)\n",
        "\n",
        "\n",
        "for method in feature_methods:\n",
        "    mean_results = {'Algorithm': list(classifiers.keys()), 'Mean Accuracy': [np.mean(accuracies[method][clf]) for clf in classifiers]}\n",
        "    mean_results_df = pd.DataFrame(mean_results)\n",
        "\n",
        "    detailed_results = {f'{clf} Accuracies': accuracies[method][clf] for clf in classifiers}\n",
        "    detailed_results_df = pd.DataFrame(detailed_results)\n",
        "    if method == 'all':\n",
        "      filename = f'model_accuracies_All_Feature.xlsx'\n",
        "    elif method == '5%':\n",
        "      filename = f'model_accuracies_5%_Feature.xlsx'\n",
        "    else:\n",
        "      filename = f'model_accuracies_1%_{method}_Feature.xlsx'\n",
        "    with pd.ExcelWriter(filename) as writer:\n",
        "        mean_results_df.to_excel(writer, sheet_name='Mean Accuracies', index=False)\n",
        "        detailed_results_df.to_excel(writer, sheet_name='Detailed Accuracies', index=False)\n",
        "\n",
        "    print(f\"Kết quả đã được ghi vào file {filename}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}